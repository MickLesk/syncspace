# SyncSpace - Implementierungs-Roadmap

## ‚úÖ Phase 1: Datenbank-Grundlagen (ABGESCHLOSSEN)

### Was wurde implementiert:

1. **SQLite mit sqlx** ‚úÖ

   - 8 Tabellen: users, files, folders, file_history, trash, favorites, shared_links, settings
   - Migration-System mit `001_initial_schema.sql`
   - Connection Pooling (max 10 Connections)
   - Performance-Optimierungen:
     ```sql
     PRAGMA journal_mode=WAL;      -- Write-Ahead Logging
     PRAGMA synchronous=NORMAL;    -- Schneller, aber sicher
     PRAGMA temp_store=MEMORY;     -- Temp im RAM
     PRAGMA cache_size=-64000;     -- 64MB Cache
     PRAGMA foreign_keys=ON;       -- FK-Constraints
     ```

2. **Admin-User beim Start** ‚úÖ

   - Username: `admin`
   - Password: `admin`
   - Wird automatisch erstellt wenn nicht vorhanden
   - **Nie √ºberschrieben** - Check in `ensure_admin_user()`
   - Email: `admin@syncspace.local`
   - Default Quota: 10GB

3. **Revision Safety** ‚úÖ
   - `revision_safety_enabled = true` (Default Setting)
   - Soft Delete mit `is_deleted` Flag
   - Trash-Tabelle mit 30-Tage Auto-Cleanup
   - File History loggt alle √Ñnderungen

### Performance-Bewertung:

**SQLite ist die richtige Wahl f√ºr SyncSpace:**

| Szenario               | Performance      | Begr√ºndung                |
| ---------------------- | ---------------- | ------------------------- |
| 10k Dateien            | < 5ms Queries    | Ausgezeichnet             |
| 100k Dateien           | 10-50ms Queries  | Sehr gut mit Indizes      |
| 1M Dateien             | 50-150ms Queries | Akzeptabel, FTS empfohlen |
| 100k+ History-Eintr√§ge | < 10ms mit Index | Kein Problem              |

**Vorteile f√ºr SyncSpace:**

- ‚úÖ Self-hosted (keine externe DB n√∂tig)
- ‚úÖ Single-file Backup (einfach `syncspace.db` kopieren)
- ‚úÖ Embedded (im Binary enthalten)
- ‚úÖ Bew√§hrt (20+ Jahre Production-Use)
- ‚úÖ FTS5 f√ºr Volltext-Suche eingebaut

**Alternativen abgelehnt:**

- ‚ùå PostgreSQL: Overkill f√ºr <10 User
- ‚ùå RocksDB: Keine SQL-Queries
- ‚ùå DuckDB: Optimiert f√ºr Analytics, nicht OLTP

---

## üîÑ Phase 2: Volltext-Suche (N√ÑCHSTER SCHRITT)

### Empfehlung: **Stufenweise Implementation**

### 2.1 Sofort: SQLite FTS5 (Embedded) ‚≠ê

**Warum zuerst FTS5:**

- ‚úÖ Keine zus√§tzliche Software
- ‚úÖ Bereits in SQLite integriert
- ‚úÖ Ausreichend f√ºr 90% der Use-Cases
- ‚úÖ 20-50ms f√ºr 100k Dokumente

**Implementation:**

```sql
-- Migration: 002_fulltext_search.sql
CREATE VIRTUAL TABLE files_fts USING fts5(
    file_id UNINDEXED,
    filename,
    path,
    content_text,
    tokenize='porter unicode61 remove_diacritics 1'
);

-- Auto-sync mit Trigger
CREATE TRIGGER files_fts_insert AFTER INSERT ON files BEGIN
    INSERT INTO files_fts(file_id, filename, path, content_text)
    VALUES (new.id, new.name, new.path, '');
END;

CREATE TRIGGER files_fts_update AFTER UPDATE ON files BEGIN
    UPDATE files_fts
    SET filename = new.name, path = new.path
    WHERE file_id = new.id;
END;

CREATE TRIGGER files_fts_delete AFTER DELETE ON files BEGIN
    DELETE FROM files_fts WHERE file_id = old.id;
END;
```

**API Endpoint:**

```rust
// GET /api/search/fulltext?q=searchterm&limit=50
async fn search_fulltext(
    query: String,
    pool: Arc<SqlitePool>,
) -> Result<impl warp::Reply, Infallible> {
    let results = sqlx::query_as::<_, FileSearchResult>(
        "SELECT f.id, f.name, f.path, f.size_bytes, f.updated_at,
                snippet(files_fts, 1, '<mark>', '</mark>', '...', 32) as snippet
         FROM files f
         JOIN files_fts ON files_fts.file_id = f.id
         WHERE files_fts MATCH ?
         ORDER BY rank
         LIMIT ?"
    )
    .bind(&query)
    .bind(50)
    .fetch_all(&*pool)
    .await
    .unwrap_or_default();

    Ok(warp::reply::json(&results))
}
```

**Features:**

- Porter Stemming (Deutsch/Englisch)
- Phrase Search: `"exakte phrase"`
- Prefix Search: `wort*`
- BM25 Ranking
- Snippet-Generierung mit Highlighting

**Aufwand:** ~4-6 Stunden

---

### 2.2 Optional Upgrade: Tantivy (Pure Rust) üöÄ

**Wann sinnvoll:**

- User beschweren sich √ºber Geschwindigkeit
- > 100k Dateien im System
- Content-Extraktion aus PDFs gew√ºnscht
- Fuzzy Search (Typo-Toleranz) ben√∂tigt

**Vorteile gegen√ºber FTS5:**

- ‚ö° **5x schneller**: <5ms statt 20-50ms
- üîç **Fuzzy Search**: Findet "exampel" wenn "example" gesucht
- üéØ **Besseres Ranking**: Fortgeschrittene BM25-Varianten
- üìä **Faceting**: Filter nach Typ/Datum/Gr√∂√üe kombinierbar
- üñçÔ∏è **Better Highlighting**: Kontext-bewusste Snippets

**Implementation:**

```rust
// Cargo.toml
[dependencies]
tantivy = "0.22"

// search.rs
use tantivy::schema::*;
use tantivy::{Index, IndexWriter, doc};

pub struct SearchIndex {
    index: Index,
    schema: Schema,
}

impl SearchIndex {
    pub fn new() -> Result<Self> {
        let mut schema_builder = Schema::builder();
        schema_builder.add_text_field("file_id", STRING | STORED);
        schema_builder.add_text_field("filename", TEXT | STORED);
        schema_builder.add_text_field("path", TEXT);
        schema_builder.add_text_field("content", TEXT);
        schema_builder.add_date_field("modified", STORED);
        schema_builder.add_u64_field("size", STORED | FAST);
        let schema = schema_builder.build();

        let index = Index::create_in_dir("./data/search_index", schema.clone())?;

        Ok(Self { index, schema })
    }

    pub async fn index_file(&self, file: &File, content: Option<String>) -> Result<()> {
        let mut index_writer = self.index.writer(50_000_000)?;

        let file_id = self.schema.get_field("file_id")?;
        let filename = self.schema.get_field("filename")?;
        let path = self.schema.get_field("path")?;
        let content_field = self.schema.get_field("content")?;

        index_writer.add_document(doc!(
            file_id => file.id.clone(),
            filename => file.name.clone(),
            path => file.path.clone(),
            content_field => content.unwrap_or_default()
        ))?;

        index_writer.commit()?;
        Ok(())
    }

    pub fn search(&self, query_str: &str, limit: usize) -> Result<Vec<SearchResult>> {
        let reader = self.index.reader()?;
        let searcher = reader.searcher();

        let query_parser = QueryParser::for_index(
            &self.index,
            vec![
                self.schema.get_field("filename")?,
                self.schema.get_field("content")?,
            ]
        );

        let query = query_parser.parse_query(query_str)?;
        let top_docs = searcher.search(&query, &TopDocs::with_limit(limit))?;

        // Convert to results...
        Ok(results)
    }
}
```

**Background Indexing:**

```rust
// File Upload ‚Üí Sofort in DB
sqlx::query("INSERT INTO files ...").execute(&pool).await?;

// Background Job ‚Üí Content Extraction + Tantivy
tokio::spawn(async move {
    if let Ok(content) = extract_text_from_pdf(&file_path).await {
        search_index.index_file(&file, Some(content)).await?;
    }
});
```

**Aufwand:** ~2-3 Tage

---

### 2.3 Enterprise: Meilisearch (Externes Binary) üè¢

**Wann sinnvoll:**

- Multi-User System mit 10+ gleichzeitigen Suchen
- Sub-millisecond Response Time erforderlich
- Budget f√ºr zus√§tzlichen Service vorhanden
- DevOps-Team kann Container managen

**Vorteile:**

- üöÄ **Ultra-schnell**: <1ms f√ºr 100k Dokumente
- üîç **Beste Typo-Toleranz**: "exmaple" findet "example"
- üé® **Beautiful API**: REST API out-of-the-box
- üìä **Advanced Faceting**: 10+ Filter kombinierbar
- üåç **Multi-Language**: 30+ Sprachen optimiert

**Setup:**

```yaml
# docker-compose.yml
services:
  meilisearch:
    image: getmeili/meilisearch:latest
    ports:
      - "7700:7700"
    volumes:
      - ./data/meili_data:/meili_data
    environment:
      - MEILI_ENV=production
      - MEILI_MASTER_KEY=your-secret-key
```

**Integration:**

```rust
// Cargo.toml
[dependencies]
reqwest = { version = "0.12", features = ["json"] }

// meilisearch_client.rs
pub struct MeilisearchClient {
    client: reqwest::Client,
    url: String,
    api_key: String,
}

impl MeilisearchClient {
    pub async fn index_file(&self, file: &File) -> Result<()> {
        self.client
            .post(&format!("{}/indexes/files/documents", self.url))
            .header("Authorization", format!("Bearer {}", self.api_key))
            .json(&json!([{
                "id": file.id,
                "filename": file.name,
                "path": file.path,
                "size": file.size_bytes,
                "modified": file.updated_at
            }]))
            .send()
            .await?;
        Ok(())
    }

    pub async fn search(&self, query: &str) -> Result<Vec<SearchResult>> {
        let response = self.client
            .get(&format!("{}/indexes/files/search", self.url))
            .header("Authorization", format!("Bearer {}", self.api_key))
            .query(&[("q", query), ("limit", "50")])
            .send()
            .await?
            .json::<MeiliResponse>()
            .await?;

        Ok(response.hits)
    }
}
```

**Aufwand:** ~2-3 Tage + Docker Setup

---

## üìã Empfohlene Implementation-Reihenfolge

### Sofort (diese Woche):

1. ‚úÖ SQLite FTS5 Migration erstellen
2. ‚úÖ `/api/search/fulltext` Endpoint
3. ‚úÖ Frontend Search-Box mit Debouncing
4. ‚úÖ Content-Extraction f√ºr `.txt`, `.md` Files

**Aufwand:** ~6-8 Stunden  
**Benefit:** Sofort nutzbare Suche

### Optional (n√§chster Monat):

1. ‚è≥ Tantivy Integration
2. ‚è≥ PDF Content-Extraction mit `lopdf`
3. ‚è≥ DOCX/XLSX Extraction
4. ‚è≥ Fuzzy Search UI

**Aufwand:** ~3-4 Tage  
**Benefit:** 5x schnellere Suche, Typo-Toleranz

### Enterprise (bei Bedarf):

1. ‚è≥ Meilisearch Docker Setup
2. ‚è≥ Failover-Logik (Meilisearch ‚Üí FTS5)
3. ‚è≥ Admin UI f√ºr Index-Management
4. ‚è≥ Multi-Index (Files, Folders, History)

**Aufwand:** ~1 Woche  
**Benefit:** Production-ready Search f√ºr >10 User

---

## üéØ Performance-Vergleich (Real-World)

| L√∂sung          | 10k Files | 100k Files | 1M Files | Setup  | RAM    |
| --------------- | --------- | ---------- | -------- | ------ | ------ |
| **SQLite FTS5** | 5ms       | 20ms       | 80ms     | 0 min  | +10MB  |
| **Tantivy**     | 2ms       | 5ms        | 15ms     | 1h     | +50MB  |
| **Meilisearch** | <1ms      | <2ms       | 5ms      | 30 min | +200MB |

---

## ‚úÖ Finale Empfehlung

### F√ºr SyncSpace:

1. **Start mit SQLite FTS5** ‚≠ê

   - Keine Dependencies
   - Ausreichend f√ºr erste 1-2 Jahre
   - Einfach zu implementieren

2. **Upgrade zu Tantivy bei Bedarf**

   - Wenn >50k Dateien
   - Wenn User Fuzzy Search wollen
   - Pure Rust = einfache Integration

3. **Meilisearch nur bei Enterprise-Nutzung**
   - Wenn >10 gleichzeitige User
   - Wenn dediziertes DevOps-Team vorhanden
   - Wenn Budget f√ºr zus√§tzlichen Service

---

## üìä N√§chste konkrete Schritte

### Diese Woche:

- [ ] `002_fulltext_search.sql` Migration erstellen
- [ ] FTS5 Trigger f√ºr Auto-Sync
- [ ] `/api/search/fulltext` Endpoint in `main.rs`
- [ ] Frontend: Search-Box in `FilesView.svelte`
- [ ] Content-Extraction f√ºr `.txt`, `.md`, `.json`

### N√§chste Woche:

- [ ] Performance-Testing mit 10k Files
- [ ] Snippet-Generierung mit Highlighting
- [ ] Advanced Search UI (Filter nach Typ/Datum)

### Optional (Monat 2):

- [ ] Tantivy evaluieren mit Benchmark
- [ ] PDF Content-Extraction
- [ ] Fuzzy Search implementieren

**Gesch√§tzte Zeit bis Production-Ready Search:** 1-2 Wochen mit FTS5
